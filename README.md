# llmon-:pie:

local cli llm chat with speech-to-text and text-to-speech support

uses llama-cpp-python, coqui.ai and pywhispercpp

gui version uses streamlit. still local
