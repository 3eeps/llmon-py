# llmon-:pie:

local cli/gui llm chat with speech-to-text and text-to-speech support

uses llama-cpp-python, coqui.ai and pywhispercpp

gui version uses streamlit. still local
